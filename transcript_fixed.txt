**東京大学サマースクール2024 LLM大規模言語モデル講座 Day2 議事録**

**開催日時:** 2024年9月11日

**講師:** 原田 憲旺（東京大学 松尾・岩澤研究室 博士課程2年）

**参加者:** 約600名

**1. 開会挨拶 (0:00:01-0:00:58)**

川崎：皆さんこんばんは。東京大学 松尾・岩澤研究室の川崎です。本日はLLM大規模言語モデル講座Day2、ライブにご参加いただきありがとうございます。前回は約1450名の方にご参加いただきましたが、今回は約600名です。後ほど参加される方もいらっしゃることを期待し、講座を始めさせていただきます。本日の講師は、松尾・岩澤研究室所属の原田さんと戸部さんです。原田さんは去年のLLM講座を受講され、現在は運営にも携わっていただいています。よろしくお願いいたします。

**2. チャットボットの使い方説明 (0:00:59-0:04:37)**

川崎：最初に、チャットボットの使い方を改めてご説明します。質疑応答はチャットボットで行います。[リンク先]からOmnicampusアカウントでログインしてください。講義内容に関する質問は、「質問をする」ボタンを押して、「講義内容」「演習内容」「その他」から質問の種類を選択し、質問を入力して送信してください。回答が得られたら「Good」ボタンを、解決しなかったら「Bad」ボタンを押してください。「Bad」ボタンを押すと運営側に通知が行き、講師または運営者が回答します。回答はメールで通知されます。1質問につき1スレッドでご利用ください。解決済みの質問は、新たなセッションを開始して質問してください。講義中にも質疑応答の時間を設けますので、ご活用ください。

**3. 演習時間について (0:04:38-0:05:13)**

川崎：本日から各回ごとに演習時間を設けます。講義90分、演習30分の予定です。演習環境はGoogle Colabを使用します。

**4. 自己紹介 (0:05:40-0:06:56)**

原田：皆さんこんばんは。本日の授業は「PromptingとRAG」です。自己紹介ですが、松尾・岩澤研究室の博士課程2年です。去年の講座立ち上げ時に講座資料作成・コンペ作成担当、GENIACでは評価担当でした。研究テーマは大規模言語モデルの文脈活用能力、Mechanistic interpretability、Lost in the middle、Instruction following、教育場面における大規模言語モデル応用、Retrieval augmented generationです。担当講座は第2回講義「PromptingとRAG」、第3回演習「Pre-training」です。よろしくお願いいたします。

**5. 講座全体像の確認 (0:06:57-0:08:03)**

原田：本日は「PromptingとRAG」、学習済みのLLMを（追加学習せずに）活用する技術についてお話します。他の講義との関係性としては、学習による性能向上は第5回、第7回、第11回で扱います。マルチモーダル情報利用や行動選択へのLLM活用は第12回です。「なぜ/どのようにLLMは成功/失敗するのか」は第10回で扱います。

**6. 本日の目的と目標 (0:08:06-0:08:50)**

原田：本日の目的は、学習済みのLLMを（追加学習せずに）活用する技術について学ぶことです。目標は、プロンプティングや文脈内学習の説明、プロンプティングによる性能改善方法の説明、Augmented Language Modelの必要性と原理の説明、Hugging Face上の公開モデルを使った基本的なプロンプティングの実装、Retrieval Augmented Generationの実装です。

**7.  前回の復習：言語モデルとは (0:08:51-0:11:35)**

原田：前回の復習です。言語モデルは、単語の系列（文章）の生成確率をモデル化したものです。自己回帰言語モデルは、条件付き確率を用いて、次の単語を予測します。学習はNext Token Predictionで行われ、予測と正解の誤差（交差エントロピー）を小さくするように学習します。現在の主要なLLMはTransformerを用いて学習されています。Transformerの内部処理は来週詳述します。様々なベンチマークで高い性能を示しており、医学知識なども保有しています。ビジネスシーンでもChatGPTやGitHub Copilotの活用により、生産性向上などの効果が報告されています。大規模言語モデルは、大規模な学習データ、大規模なモデル、大規模な計算資源を用いて学習されます。

**8. モデルの種類 (0:11:37-0:13:43)**

原田：モデルには、非公開モデル（PaLM、Gopherなど）、APIのみ利用可能なモデル（GPT、Gemini、Claudeなど）、公開モデル（Llama、Mistral、Bloom、Falconなど）があります。公開モデルは重みまで公開されており、分析やFine-Tuningに適しています。

**9. モデルの選び方 (0:13:46-0:15:40)**

原田：どのモデルを使うべきか？  考慮すべき点は、学習データ、モデル構造、コンテキスト長、既存ベンチマークでの性能、推論コスト、ライセンスです。ベンチマークとしては、Open LLM leaderboard、Chatbot Arena、Nejumi Leaderboardなどがあります。

**10. モデルの評価 (0:15:43-0:17:07)**

原田：Nejumi Leaderboardは日本語ベンチマークです。自分で評価する際には、simple-evals/evals、llm-jp-eval、lm-evaluation-harnessなどのツールがあります。プロンプトの違いでスコアが大きく変わることに注意してください。

**11. API利用とライブラリ (0:17:07-0:18:47)**

原田：OpenAIのAPI利用例、transformersライブラリ（Hugging Face）について説明しました。

**12. 学習済みモデルを活用する技術 (0:18:47-0:19:17)**

原田：学習済みモデルを活用する技術は大きく分けて2つあります。1つ目は単一モデルでの工夫（プロンプティング）、2つ目は外部ツール/知識の利用（Augmented LM）です。

**13.  Prompting (0:19:20-0:27:03)**

原田：LLMは指示に応じた返答をします。QAやセンチメント分析などのタスクに適用できますが、必ずしも期待通りの出力が得られるとは限りません。Promptingは、特定の機能の発生を促進するような入力文です。Few-Shot Promptingは、タスク指示文とデモンストレーション例を入力する手法です。モデルが大規模なほど、Few-Shot Promptingの効果が大きくなります。これは文脈内学習(In-Context Learning, ICL)と呼ばれます。ICLはパラメータを更新せず、条件付けにより予測を修正します。従来のFine-Tuningとの違いを説明しました。プロンプトの重要性、指示文の違いの影響について、AG Newsデータセットを用いた実験結果を示しました。プロンプトによって性能が30%変化することを示しました。


**14.  Few-Shot Promptingと文脈内学習の深堀り (0:27:03-0:28:23)**

原田：デモンストレーション例を増やすと性能が向上します。Many-Shot In-Context Learningに関する研究を紹介しました。Chain-of-Thought (CoT) Promptingは、思考過程を含めることで推論タスクの性能を向上させる手法です。

**15. Chain-of-Thought (CoT) Prompting (0:28:24-0:30:19)**

原田：CoT Promptingの例を示し、モデルサイズが大きいほど効果が大きいことを説明しました。

**16. Zero-Shot Chain-of-Thought (0:30:37-0:32:15)**

原田：Zero-Shot CoT Promptingは、事例なしで思考過程を促す手法です。"Let's think step by step"などの指示文が有効です。

**17. Zero-Shot CoTの改善 (0:32:16-0:33:20)**

原田：LLMを使った自動プロンプト探索、Plan-and-Solve Promptingなどの手法を紹介しました。

**18. Decodingの工夫 (0:33:23-0:36:25)**

原田：Self-Consistency、Tree of ThoughtsなどのDecodingの工夫により、性能を向上させることができます。

**19. Prompting/文脈内学習のまとめ (0:36:28-0:38:15)**

原田：プロンプティングのまとめと、参考文献を紹介しました。LLM-as-a-Judge、敵対的プロンプト(Adversarial Prompt)についても簡単に触れました。

**20. 質疑応答1 (0:39:57-0:47:30)**

(スライド資料の最新版、Gopherモデル、Prompting手法の概要、回答のばらつき、LLMによるプロンプト自動生成、マジョリティボーティング)


**21. Augmented Language Models (0:47:32-1:01:51)**

原田：Augmented Language Modelsについて説明しました。外部ツールや知識を利用することで、学習効率、知識の更新、信頼性を向上させることができます。Retrieval Augmented Language Models (RAG)は、外部データベースの検索とLLMを組み合わせたモデルです。Retriever、Sparse Retriever、Dense Retriever、Rerank、Generationについて説明しました。REPLUG、In-Context RALM、KNN-Promptなどの手法を紹介し、実験結果を示しました。RetrieverのFine-Tuning (REPLUG LSR)についても説明しました。様々な手法があり、タスクに応じて適切な手法を選ぶことが重要です。

**22.  RAG応用例と補足事項 (1:01:54-1:07:38)**

原田：arXiv Interpreterの例を紹介しました。データベース、効率的な検索方法、RetrieverとLLMの学習についても補足説明を行いました。Long context LLM、Long context LLMに関連する問題点(Lost in the Middleなど)について説明しました。

**23. 質疑応答2 (1:19:16-1:28:24)**

(RAGの使い方、マルチモーダルRAG、RAGの将来性、外部情報と内部情報の優先度、データセット作成方法、Hallucination問題、データ構造化)

**24. Tool-useとAgent (1:07:40-1:18:25)**

原田：Tool-useとAgentについて説明しました。Tool Augmented Language Modelsは、外部ツールで拡張されたLLMです。検索、コード実行環境、API、別のモデルなどをツールとして使用します。TALM、PAL、ToolFormer、ToolkenGPT、Chameleonなどの研究例を紹介しました。LLMをツールとして役割分担させる手法、研究ワークフローの自動化についても説明しました。

**25.  演習開始 (1:32:32-1:58:09)**

戸部：演習環境（Google Colab）の使い方を説明し、Hugging Faceからのモデル読み込み、Promptingテクニックの実装、RAGの実装を行いました。Zero-Shot、Few-Shot、Chain-of-Thought Promptingの実装例を示しました。リランキングについても説明しました。

**26. 質疑応答3 (1:54:48-1:58:09)**

(サンプルフォース、Google Colabの有料版コスト、モデルダウンロード失敗、RAG)

**27. 宿題の説明 (1:58:45-2:02:41)**

川崎：宿題について説明しました。Google Colabを用いて、演習で扱った内容を実際に実装します。提出方法はOmnicampusです。松尾研のLLMコミュニティのWikipedia風のページを作成し、ナレッジ共有を行うことを提案しました。

**28. 閉会挨拶 (2:02:41-2:03:23)**

川崎、戸部：閉会挨拶とアンケートへの回答のお願い、宿題の提出期限について説明しました。


**(参考資料):** スライド資料に記載の参考文献全て


**注意事項:** 本議事録は、東京大学 松尾・岩澤研究室が作成したスライド資料を元に作成されており、クリエイティブ・コモンズのCC BY-NC-SA 4.0 DEED(表示 – 非営利 – 継承 4.0 国際)のライセンスが適用されます。再利用する際には、ライセンス表記を含めてください。また、参照論文等の引用がある場合は、スライド資料のReferenceを参照してください。営利目的での利用は、東京大学 松尾・岩澤研究室にお問い合わせください。
